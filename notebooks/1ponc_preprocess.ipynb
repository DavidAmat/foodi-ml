{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47093e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "#os.chdir(\"/home/ec2-user/SageMaker/foodi-ml/notebooks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d63465",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/ec2-user/SageMaker/foodi-ml/\")\n",
    "from retrieval.data.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd332a7c",
   "metadata": {},
   "source": [
    "# Exploration of execution\n",
    "\n",
    "Execution \n",
    "\n",
    "```{bash}\n",
    "cd /home/ec2-user/SageMaker/foodi-ml\n",
    "source activate python3\n",
    "export DATA_PATH=/home/ec2-user/SageMaker/dataset/\n",
    "python run.py options/adapt/foodi-ml/i2t.yaml\n",
    "\n",
    "#watch -n 1 \"nvidia-smi\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c6b24",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e861d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = '/home/ec2-user/SageMaker/dataset/'\n",
    "PATH_FOODI = '/home/ec2-user/SageMaker/foodi-ml'\n",
    "DATASET_CSV = 'glovo-foodi-ml-dataset.csv'\n",
    "\n",
    "conf = {\n",
    "    \"S3_BUCKET\": 'glovo-products-dataset-d1c9720d',\n",
    "    \"S3_KEY_DATASET\": DATASET_CSV,\n",
    "    \"LOCAL_RAW_DATASET\": os.path.join(PATH_DATA, DATASET_CSV),\n",
    "    \"LOCAL_DATASET\": os.path.join(PATH_DATA, 'samples'),\n",
    "    \"LOCAL_IMAGES\": os.path.join(PATH_DATA, 'dataset'),\n",
    "    \"LOCAL_VOCAB\": os.path.join(PATH_FOODI, '.vocab_cache/foodiml_vocab.json'),\n",
    "    \"pth_dwn_samples\": '/home/ec2-user/SageMaker/dataset/',\n",
    "    \"pth_dwn_images\": '/home/ec2-user/SageMaker/dataset/dataset/',\n",
    "    \"pth_vocab\": '/home/ec2-user/SageMaker/foodi-ml/.vocab_cache/foodiml_vocab.json',\n",
    "    \"pth_dataset_json\": '/home/ec2-user/SageMaker/dataset/dataset_foodiml.json',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02bd6a",
   "metadata": {},
   "source": [
    "# Read all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabe783a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d69e678e7a44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOCAL_RAW_DATASET'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \"\"\"\n\u001b[1;32m    532\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples = pd.read_csv(os.path.join(conf['LOCAL_RAW_DATASET']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "65f1ea12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/dataset/dataset/NZTCKFL_0017467_1193055503.png'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[\"s3_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbbb052",
   "metadata": {},
   "source": [
    "## 1) Create sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "57d52247",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[\"sentence\"] = \\\n",
    "    np.where(samples[\"product_name\"], samples[\"product_name\"].astype(str), \"\") + \" \" + \\\n",
    "    np.where(samples[\"collection_section\"], samples[\"collection_section\"].astype(str), \"\") + \" \" + \\\n",
    "    np.where(samples[\"product_description\"], samples[\"product_description\"].astype(str), \"\")\n",
    "\n",
    "samples[\"sentence\"] = samples[\"sentence\"].str.lower()\n",
    "samples.rename(columns={'Unnamed: 0': 'idx'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6652ad",
   "metadata": {},
   "source": [
    "### 1.1) Fit tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4196b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH_FOODI)\n",
    "from retrieval.data.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91b2ad27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 1) Get all sentences \n",
    "sentences = samples[\"sentence\"].values\n",
    "\n",
    "# 2) Fit Tokenizer with senteces (CAREFUL, takes 6-7 min)\n",
    "tokenizer = Tokenizer(vocab_path=None, download_tokenizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "100c91a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2887444/2887444 [06:46<00:00, 7094.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fit tokenize\n",
    "vocab = tokenizer.fit(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c61ae05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245967"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39907cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 334 ms, sys: 0 ns, total: 334 ms\n",
      "Wall time: 341 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3) Saving vocabulary\n",
    "tokenizer.save(conf['LOCAL_VOCAB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee6d919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245967"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Load if already saved\n",
    "tokenizer = tokenizer.load(conf['LOCAL_VOCAB'])\n",
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5c4a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# LOAD equivalent\n",
    "tokenizer_2 = Tokenizer(vocab_path=conf[\"pth_vocab\"], download_tokenizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d620948a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245967"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer_2.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31b76fa",
   "metadata": {},
   "source": [
    "### 1.2) Creating dataset parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "259e8b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only necessary columns for modelling\n",
    "final_samples = samples[[\"sentence\", \"s3_path\", \"subset\"]].reset_index().copy()\n",
    "final_samples.rename(columns={\"sentence\": \"caption\"}, inplace=True)\n",
    "final_samples.rename(columns={\"subset\": \"split\"}, inplace=True)\n",
    "final_samples.rename(columns={\"index\": \"img_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0f5d80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous version\n",
    "if os.path.exists(conf[\"LOCAL_DATASET\"]):\n",
    "    shutil.rmtree(conf[\"LOCAL_DATASET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4a053d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as partitioned parquet\n",
    "final_samples.to_parquet(\n",
    "    path=conf[\"LOCAL_DATASET\"],\n",
    "    engine=\"pyarrow\",\n",
    "    index=False,\n",
    "    partition_cols=[\"split\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da8d48",
   "metadata": {},
   "source": [
    "## Creating dataset json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a4e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_parquet(os.path.join(conf['pth_dwn_samples'], \"samples\"), engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c0e917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/dataset/dataset/CBNGZLF_0013607_1049265587.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[\"s3_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf620cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_id', 'caption', 's3_path', 'split'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5cc19",
   "metadata": {},
   "source": [
    "## Samples for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19119ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train', 'val']\n",
       "Categories (3, object): ['test', 'train', 'val']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.split.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a2a8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train = samples[samples[\"split\"]==\"train\"].sample(7000)\n",
    "samples_eval = samples[samples[\"split\"]==\"val\"].sample(1500)\n",
    "samples_test = samples[samples[\"split\"]==\"test\"].sample(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bbde5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_dataset = pd.concat([samples_train, samples_eval, samples_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fad5d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_id', 'caption', 's3_path', 'split'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfb76534",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = mock_dataset.s3_path.to_list()\n",
    "# shutil.copy(image_paths[0], \"/home/ec2-user/SageMaker/dataset/mock_dataset\") # test OK\n",
    "\n",
    "for item in image_paths:\n",
    "    shutil.copy(item, \"/home/ec2-user/SageMaker/dataset/mock_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3035d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_dataset.to_csv(\"/home/ec2-user/SageMaker/dataset/mock_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9260b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "527f4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dataset = {\n",
    "    \"images\": [],\n",
    "    \"dataset\": \"foodiml\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "10442c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [00:01, 2189.07it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(samples.iterrows()):\n",
    "    if i>2500:\n",
    "        break\n",
    "    raw_sentence = row[\"caption\"]\n",
    "    filename = row[\"s3_path\"].split(\"/\")[-1]\n",
    "    sentence_tokens = tokenizer.split_sentence(raw_sentence)\n",
    "    sentence_json = {}\n",
    "    sentence_json[\"imgid\"] = i\n",
    "    sentence_json[\"sentences\"] = [\n",
    "        {\n",
    "            \"tokens\": sentence_tokens,\n",
    "            \"raw\": raw_sentence,\n",
    "            \"imgid\": i\n",
    "        }\n",
    "    ]\n",
    "    sentence_json[\"split\"] = row[\"split\"]\n",
    "    sentence_json[\"filename\"] = filename\n",
    "    samples_dataset[\"images\"].append(sentence_json)\n",
    "    #print(\"raw sentence: \", raw_sentence)\n",
    "    #print(\"filename: \", filename)\n",
    "    #print(\"sentence_tokens :\", sentence_tokens)\n",
    "    #print(\"sentence_json: \", sentence_json)\n",
    "    #print(\"samples_dataset:\", samples_dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8c7d2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset_foodiml.json \n",
    "with open(\"/home/ec2-user/SageMaker/dataset/foodiml_json.json\", \"w\") as f:\n",
    "    json.dump(samples_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab4171e",
   "metadata": {},
   "source": [
    "# GloVE (in case we want to retrain a new GloVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91d435a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: glove_python in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.1.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from glove_python) (1.5.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from glove_python) (1.16.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install glove_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "58319a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5f18b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a corpus object\n",
    "corpus = Corpus() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "22217a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_id', 'caption', 's3_path', 'split'], dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5d1d9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(samples[\"caption\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "89b769aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2887444/2887444 [06:27<00:00, 7449.51it/s]\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "for sentence in tqdm(sentences):\n",
    "    lines.append(tokenizer.split_sentence(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "41b326c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 317 ms, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
    "corpus.fit(lines, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "228dafa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "glove = Glove(no_components=300, learning_rate=0.05) # no_components=300 as in abstract.yaml\n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "glove.save('/home/ec2-user/SageMaker/dataset/glove-foodiml.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f838f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
