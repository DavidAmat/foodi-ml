{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40db811a",
   "metadata": {},
   "source": [
    "# Exploration of execution\n",
    "\n",
    "Execution \n",
    "\n",
    "```{bash}\n",
    "cd /home/ec2-user/SageMaker/foodi-ml\n",
    "source activate python3\n",
    "export DATA_PATH=/home/ec2-user/SageMaker/data/\n",
    "python run.py options/adapt/foodi-ml/i2t.yaml\n",
    "\n",
    "#watch -n 1 \"nvidia-smi\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0325130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/ec2-user/SageMaker/foodi-ml/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74a4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23935df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c13531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from addict import Dict\n",
    "\n",
    "import params\n",
    "from retrieval.train import train\n",
    "from retrieval.utils import helper\n",
    "from retrieval.model import loss\n",
    "from retrieval.model.model import Retrieval\n",
    "from retrieval.data.loaders import get_loaders\n",
    "from retrieval.utils.logger import create_logger\n",
    "from retrieval.utils.helper import load_model\n",
    "from retrieval.utils.file_utils import load_yaml_opts, parse_loader_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24c3a7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b686ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(opt):\n",
    "    if 'DATA_PATH' not in os.environ:\n",
    "        if not opt.dataset.data_path:\n",
    "            raise Exception('''\n",
    "                DATA_PATH not specified.\n",
    "                Please, run \"$ export DATA_PATH=/path/to/dataset\"\n",
    "                or add path to yaml file\n",
    "            ''')\n",
    "        return opt.dataset.data_path\n",
    "    else:\n",
    "        return os.environ['DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79746d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizers(train_loader):\n",
    "    tokenizers = train_loader.dataset.tokenizer\n",
    "    if type(tokenizers) != list:\n",
    "        tokenizers = [tokenizers]\n",
    "    return tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8165a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_criterion(opt, model):\n",
    "    if 'name' in opt.criterion:\n",
    "        logger.info(opt.criterion)\n",
    "        multimodal_criterion = loss.get_loss(**opt.criterion)\n",
    "        multilanguage_criterion = loss.get_loss(**opt.criterion)\n",
    "    else:\n",
    "        multimodal_criterion = loss.ContrastiveLoss(**opt.criterion)\n",
    "        multilanguage_criterion = loss.ContrastiveLoss(**opt.ml_criterion)\n",
    "    set_model_criterion(opt, model, multilanguage_criterion, multimodal_criterion)\n",
    "    # return multimodal_criterion, multilanguage_criterion\n",
    "\n",
    "\n",
    "def set_model_criterion(opt, model, multilanguage_criterion, multimodal_criterion):\n",
    "    model.mm_criterion = multimodal_criterion\n",
    "    model.ml_criterion = None\n",
    "    if len(opt.dataset.adapt.data) > 0:\n",
    "        model.ml_criterion = multilanguage_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469771a7",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1db798",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATA_PATH\"] = \"/home/ec2-user/SageMaker/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ab0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = \"options/adapt/foodi-ml/i2t.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f90822",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"options\": options,\n",
    "}\n",
    "args = Dict(args)\n",
    "opt = load_yaml_opts(args.options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e920b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = create_logger(level='debug' if opt.engine.debug else 'info')\n",
    "#logger.info(f'Used args   : \\n{args}')\n",
    "#logger.info(f'Used options: \\n{opt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1db8ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path of the data\n",
    "data_path = get_data_path(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53ed4276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 11:15:35,822 - [INFO    ] - Loaded vocab containing 245967 tokens\n",
      "2021-09-15 11:15:35,823 - [INFO    ] - Loaded from .vocab_cache/foodiml_vocab.json.\n",
      "2021-09-15 11:15:35,823 - [INFO    ] - Created tokenizer with init 245967 tokens.\n",
      "2021-09-15 11:15:37,044 - [INFO    ] - [FoodiML] Loaded 14052 images annotated \n",
      "2021-09-15 11:15:37,232 - [INFO    ] - Loaded vocab containing 245967 tokens\n",
      "2021-09-15 11:15:37,233 - [INFO    ] - Loaded from .vocab_cache/foodiml_vocab.json.\n",
      "2021-09-15 11:15:37,233 - [INFO    ] - Created tokenizer with init 245967 tokens.\n",
      "2021-09-15 11:15:37,479 - [INFO    ] - [FoodiML] Loaded 2897 images annotated \n",
      "2021-09-15 11:15:37,482 - [INFO    ] - Adapt loaders: 0\n"
     ]
    }
   ],
   "source": [
    "# Get loaders\n",
    "train_loader, val_loaders, adapt_loaders = get_loaders(data_path, args.local_rank, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76edec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = get_tokenizers(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "513be696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 11:15:39,056 - [INFO    ] - Image encoder created: ('full_image',)\n",
      "2021-09-15 11:15:41,290 - [INFO    ] - Text encoder created: gru_glove\n",
      "2021-09-15 11:15:41,429 - [INFO    ] - Created similarity: AdaptiveEmbeddingI2T(\n",
      "  (norm): Normalization(\n",
      "    (norm): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  )\n",
      "  (adapt_txt): ADAPT(\n",
      "    (fc_gamma): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    )\n",
      "    (fc_beta): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fovea): Fovea(smooth=10,train_smooth: False)\n",
      ")\n",
      "2021-09-15 11:15:41,430 - [INFO    ] - Created similarity: AdaptiveEmbeddingI2T_eval(\n",
      "  (norm): Normalization(\n",
      "    (norm): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  )\n",
      "  (adapt_txt): ADAPT(\n",
      "    (fc_gamma): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    )\n",
      "    (fc_beta): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fovea): Fovea(smooth=10,train_smooth: False)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new similarity class initialised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 11:15:44,486 - [INFO    ] - Setting devices: img: cuda,txt: cuda, loss: cuda\n",
      "2021-09-15 11:15:44,486 - [INFO    ] - Using similarity: ('adapt_i2t',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.53 s, sys: 1.6 s, total: 7.13 s\n",
      "Wall time: 7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Retrieval(**opt.model, tokenizers=tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fc6721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_fn = (lambda x: x) if not model.master else tqdm.write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34e50c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_criterion(opt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00118c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = train.Trainer(\n",
    "        model=model,\n",
    "        args=opt,\n",
    "        sysoutlog=print_fn,\n",
    "        path=opt.exp.outpath,\n",
    "        world_size=1 # TODO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0967452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 11:15:44,535 - [INFO    ] - lr 0.001\n",
      "2021-09-15 11:15:44,536 - [INFO    ] - [0.5, 2.0, 4000]\n",
      "2021-09-15 11:15:44,536 - [INFO    ] - [10000, 20000, 3000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing model.txt_enc.embed.glove\n",
      "lr: 0.001, #layers: 478, #params: 172,889,812\n",
      "Total Params: 246,679,912, \n"
     ]
    }
   ],
   "source": [
    "trainer.setup_optim(\n",
    "        lr=opt.optimizer.lr,\n",
    "        lr_scheduler=opt.optimizer.lr_scheduler,\n",
    "        clip_grad=opt.optimizer.grad_clip,\n",
    "        log_grad_norm=False,\n",
    "        log_histograms=False,\n",
    "        optimizer=opt.optimizer,\n",
    "        freeze_modules=opt.model.freeze_modules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21a523c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "logs/foodi-ml/adapt_i2t/ already exists! Do you want to rewrite it? [y/n]  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Steps :   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
      "Steps :   0%|          | 1/469 [00:06<50:22,  6.46s/it]\u001b[A\n",
      "Steps :   0%|          | 2/469 [00:07<28:59,  3.72s/it]\u001b[A\n",
      "Steps :   1%|          | 3/469 [00:08<21:49,  2.81s/it]\u001b[A\n",
      "Steps :   1%|          | 4/469 [00:09<18:15,  2.36s/it]\u001b[A\n",
      "Steps :   1%|          | 5/469 [00:10<16:09,  2.09s/it]\u001b[A\n",
      "Steps :   1%|▏         | 6/469 [00:11<14:43,  1.91s/it]\u001b[A\n",
      "Steps :   1%|▏         | 7/469 [00:12<13:43,  1.78s/it]\u001b[A\n",
      "Steps :   2%|▏         | 8/469 [00:13<12:55,  1.68s/it]\u001b[A\n",
      "                                              1.61s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [00:15<?, ?it/s]         \n",
      "Steps :   2%|▏         | 9/469 [00:15<13:13,  1.72s/it]\u001b[A\n",
      "Steps :   2%|▏         | 10/469 [00:15<11:52,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.971925, Countdown:  50.000000, Epoch:   0.000000, Iteration:  10.000000, K:   0.086441, Loss: 319.261261, Lr_Base:   0.000504, Norm: 685.981467, Total_Loss: 319.261261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   2%|▏         | 11/469 [00:16<11:29,  1.50s/it]\u001b[A\n",
      "Steps :   3%|▎         | 12/469 [00:17<11:10,  1.47s/it]\u001b[A\n",
      "Steps :   3%|▎         | 13/469 [00:18<10:52,  1.43s/it]\u001b[A\n",
      "Steps :   3%|▎         | 14/469 [00:19<10:35,  1.40s/it]\u001b[A\n",
      "Steps :   3%|▎         | 15/469 [00:20<10:22,  1.37s/it]\u001b[A\n",
      "Steps :   3%|▎         | 16/469 [00:21<10:08,  1.34s/it]\u001b[A\n",
      "Steps :   4%|▎         | 17/469 [00:22<09:58,  1.32s/it]\u001b[A\n",
      "Steps :   4%|▍         | 18/469 [00:23<09:54,  1.32s/it]\u001b[A\n",
      "                                               1.30s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [00:25<?, ?it/s]          \n",
      "Steps :   4%|▍         | 19/469 [00:25<10:07,  1.35s/it]\u001b[A\n",
      "Steps :   4%|▍         | 20/469 [00:25<09:35,  1.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.884861, Countdown:  50.000000, Epoch:   0.000000, Iteration:  20.000000, K:   0.165410, Loss: 294.108215, Lr_Base:   0.000508, Norm: 724.500198, Total_Loss: 294.108215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   4%|▍         | 21/469 [00:26<09:28,  1.27s/it]\u001b[A\n",
      "Steps :   5%|▍         | 22/469 [00:27<09:21,  1.26s/it]\u001b[A\n",
      "Steps :   5%|▍         | 23/469 [00:28<09:15,  1.25s/it]\u001b[A\n",
      "Steps :   5%|▌         | 24/469 [00:29<09:08,  1.23s/it]\u001b[A\n",
      "Steps :   5%|▌         | 25/469 [00:30<09:04,  1.23s/it]\u001b[A\n",
      "Steps :   6%|▌         | 26/469 [00:31<08:59,  1.22s/it]\u001b[A\n",
      "Steps :   6%|▌         | 27/469 [00:32<08:57,  1.22s/it]\u001b[A\n",
      "Steps :   6%|▌         | 28/469 [00:33<08:54,  1.21s/it]\u001b[A\n",
      "                                               1.20s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [00:36<?, ?it/s]          \n",
      "Steps :   6%|▌         | 29/469 [00:36<09:06,  1.24s/it]\u001b[A\n",
      "Steps :   6%|▋         | 30/469 [00:36<08:47,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   1.026769, Countdown:  50.000000, Epoch:   0.000000, Iteration:  30.000000, K:   0.237553, Loss: 268.784546, Lr_Base:   0.000511, Norm: 762.339800, Total_Loss: 268.784546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   7%|▋         | 31/469 [00:36<08:42,  1.19s/it]\u001b[A\n",
      "Steps :   7%|▋         | 32/469 [00:38<08:39,  1.19s/it]\u001b[A\n",
      "Steps :   7%|▋         | 33/469 [00:38<08:34,  1.18s/it]\u001b[A\n",
      "Steps :   7%|▋         | 34/469 [00:39<08:31,  1.18s/it]\u001b[A\n",
      "Steps :   7%|▋         | 35/469 [00:40<08:27,  1.17s/it]\u001b[A\n",
      "Steps :   8%|▊         | 36/469 [00:41<08:23,  1.16s/it]\u001b[A\n",
      "Steps :   8%|▊         | 37/469 [00:42<08:20,  1.16s/it]\u001b[A\n",
      "Steps :   8%|▊         | 38/469 [00:43<08:17,  1.15s/it]\u001b[A\n",
      "                                               1.15s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [00:45<?, ?it/s]          \n",
      "Steps :   8%|▊         | 39/469 [00:45<08:24,  1.17s/it]\u001b[A\n",
      "Steps :   9%|▊         | 40/469 [00:45<08:10,  1.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.891554, Countdown:  50.000000, Epoch:   0.000000, Iteration:  40.000000, K:   0.303460, Loss: 250.043564, Lr_Base:   0.000515, Norm: 655.773358, Total_Loss: 250.043564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   9%|▊         | 41/469 [00:46<08:07,  1.14s/it]\u001b[A\n",
      "Steps :   9%|▉         | 42/469 [00:47<08:05,  1.14s/it]\u001b[A\n",
      "Steps :   9%|▉         | 43/469 [00:48<08:02,  1.13s/it]\u001b[A\n",
      "Steps :   9%|▉         | 44/469 [00:49<08:00,  1.13s/it]\u001b[A\n",
      "Steps :  10%|▉         | 45/469 [00:50<07:57,  1.13s/it]\u001b[A\n",
      "Steps :  10%|▉         | 46/469 [00:51<07:54,  1.12s/it]\u001b[A\n",
      "Steps :  10%|█         | 47/469 [00:52<07:51,  1.12s/it]\u001b[A\n",
      "Steps :  10%|█         | 48/469 [00:53<07:49,  1.12s/it]\u001b[A\n",
      "                                               1.11s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [00:55<?, ?it/s]          \n",
      "Steps :  10%|█         | 49/469 [00:55<07:55,  1.13s/it]\u001b[A\n",
      "Steps :  11%|█         | 50/469 [00:55<07:45,  1.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.910376, Countdown:  50.000000, Epoch:   0.000000, Iteration:  50.000000, K:   0.363670, Loss: 230.083801, Lr_Base:   0.000519, Norm: 600.548945, Total_Loss: 230.083801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :  11%|█         | 51/469 [00:56<07:43,  1.11s/it]\u001b[A\n",
      "Steps :  11%|█         | 52/469 [00:57<07:41,  1.11s/it]\u001b[A\n",
      "Steps :  11%|█▏        | 53/469 [00:58<07:38,  1.10s/it]\u001b[A\n",
      "Steps :  12%|█▏        | 54/469 [00:59<07:37,  1.10s/it]\u001b[A\n",
      "Steps :  12%|█▏        | 55/469 [01:00<07:35,  1.10s/it]\u001b[A\n",
      "Steps :  12%|█▏        | 56/469 [01:01<07:34,  1.10s/it]\u001b[A\n",
      "Steps :  12%|█▏        | 57/469 [01:02<07:33,  1.10s/it]\u001b[A\n",
      "Steps :  12%|█▏        | 58/469 [01:03<07:31,  1.10s/it]\u001b[A\n",
      "                                               1.10s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [01:05<?, ?it/s]          \n",
      "Steps :  13%|█▎        | 59/469 [01:05<07:36,  1.11s/it]\u001b[A\n",
      "Steps :  13%|█▎        | 60/469 [01:05<07:27,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.947669, Countdown:  50.000000, Epoch:   0.000000, Iteration:  60.000000, K:   0.418675, Loss: 206.502167, Lr_Base:   0.000523, Norm: 478.541279, Total_Loss: 206.502167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :  13%|█▎        | 61/469 [01:06<07:26,  1.09s/it]\u001b[A\n",
      "Steps :  13%|█▎        | 62/469 [01:07<07:24,  1.09s/it]\u001b[A\n",
      "Steps :  13%|█▎        | 63/469 [01:08<07:22,  1.09s/it]\u001b[A\n",
      "Steps :  14%|█▎        | 64/469 [01:09<07:21,  1.09s/it]\u001b[A\n",
      "Steps :  14%|█▍        | 65/469 [01:10<07:19,  1.09s/it]\u001b[A\n",
      "Steps :  14%|█▍        | 66/469 [01:11<07:17,  1.09s/it]\u001b[A\n",
      "Steps :  14%|█▍        | 67/469 [01:12<07:15,  1.08s/it]\u001b[A\n",
      "Steps :  14%|█▍        | 68/469 [01:13<07:13,  1.08s/it]\u001b[A\n",
      "                                               1.08s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [01:15<?, ?it/s]          \n",
      "Steps :  15%|█▍        | 69/469 [01:15<07:18,  1.10s/it]\u001b[A\n",
      "Steps :  15%|█▍        | 70/469 [01:15<07:11,  1.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   1.012359, Countdown:  50.000000, Epoch:   0.000000, Iteration:  70.000000, K:   0.468925, Loss: 190.604874, Lr_Base:   0.000526, Norm: 537.942991, Total_Loss: 190.604874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :  15%|█▌        | 71/469 [01:16<07:09,  1.08s/it]\u001b[A\n",
      "Steps :  15%|█▌        | 72/469 [01:17<07:08,  1.08s/it]\u001b[A\n",
      "Steps :  16%|█▌        | 73/469 [01:18<07:06,  1.08s/it]\u001b[A\n",
      "Steps :  16%|█▌        | 74/469 [01:19<07:05,  1.08s/it]\u001b[A\n",
      "Steps :  16%|█▌        | 75/469 [01:20<07:03,  1.08s/it]\u001b[A\n",
      "Steps :  16%|█▌        | 76/469 [01:21<07:02,  1.07s/it]\u001b[A\n",
      "Steps :  16%|█▋        | 77/469 [01:22<07:01,  1.07s/it]\u001b[A\n",
      "Steps :  17%|█▋        | 78/469 [01:23<06:59,  1.07s/it]\u001b[A\n",
      "                                               1.07s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [01:25<?, ?it/s]          \n",
      "Steps :  17%|█▋        | 79/469 [01:25<07:03,  1.09s/it]\u001b[A\n",
      "Steps :  17%|█▋        | 80/469 [01:25<06:56,  1.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.930950, Countdown:  50.000000, Epoch:   0.000000, Iteration:  80.000000, K:   0.514832, Loss: 189.690567, Lr_Base:   0.000530, Norm: 374.068432, Total_Loss: 189.690567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :  17%|█▋        | 81/469 [01:26<06:55,  1.07s/it]\u001b[A\n",
      "Steps :  17%|█▋        | 82/469 [01:27<06:53,  1.07s/it]\u001b[A\n",
      "Steps :  18%|█▊        | 83/469 [01:28<06:52,  1.07s/it]\u001b[A\n",
      "Steps :  18%|█▊        | 84/469 [01:29<06:51,  1.07s/it]\u001b[A\n",
      "Steps :  18%|█▊        | 85/469 [01:30<06:49,  1.07s/it]\u001b[A\n",
      "Steps :  18%|█▊        | 86/469 [01:31<06:48,  1.07s/it]\u001b[A\n",
      "Steps :  19%|█▊        | 87/469 [01:32<06:47,  1.07s/it]\u001b[A\n",
      "Steps :  19%|█▉        | 88/469 [01:33<06:46,  1.07s/it]\u001b[A\n",
      "                                               1.07s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [01:35<?, ?it/s]          \n",
      "Steps :  19%|█▉        | 89/469 [01:35<06:49,  1.08s/it]\u001b[A\n",
      "Steps :  19%|█▉        | 90/469 [01:35<06:43,  1.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.983562, Countdown:  50.000000, Epoch:   0.000000, Iteration:  90.000000, K:   0.556770, Loss: 164.150513, Lr_Base:   0.000534, Norm: 395.810625, Total_Loss: 164.150513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :  19%|█▉        | 91/469 [01:36<06:42,  1.06s/it]\u001b[A\n",
      "Steps :  20%|█▉        | 92/469 [01:37<06:41,  1.06s/it]\u001b[A\n",
      "Steps :  20%|█▉        | 93/469 [01:38<06:39,  1.06s/it]\u001b[A\n",
      "Steps :  20%|██        | 94/469 [01:39<06:38,  1.06s/it]\u001b[A\n",
      "Steps :  20%|██        | 95/469 [01:40<06:37,  1.06s/it]\u001b[A\n",
      "Steps :  20%|██        | 96/469 [01:41<06:36,  1.06s/it]\u001b[A\n",
      "Steps :  21%|██        | 97/469 [01:42<06:34,  1.06s/it]\u001b[A\n",
      "Steps :  21%|██        | 98/469 [01:43<06:33,  1.06s/it]\u001b[A\n",
      "                                               1.06s/it]\u001b[A\n",
      "Epochs:   0%|          | 0/10 [01:46<?, ?it/s]          \n",
      "Steps :  21%|██        | 99/469 [01:46<06:36,  1.07s/it]\u001b[A\n",
      "Steps :  21%|██▏       | 100/469 [01:46<06:31,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.994153, Countdown:  50.000000, Epoch:   0.000000, Iteration: 100.000000, K:   0.595084, Loss: 149.425079, Lr_Base:   0.000538, Norm: 383.481084, Total_Loss: 149.425079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :  22%|██▏       | 101/469 [01:47<06:30,  1.06s/it]\u001b[A\n",
      "Steps :  22%|██▏       | 102/469 [01:48<06:29,  1.06s/it]\u001b[A\n",
      "Steps :  22%|██▏       | 103/469 [01:49<06:28,  1.06s/it]\u001b[A\n",
      "Steps :  22%|██▏       | 104/469 [01:50<06:27,  1.06s/it]\u001b[A\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fb0f5dc0a185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalid_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/train/train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, valid_loaders, lang_loaders, init_iteration, nb_epochs, log_interval, valid_interval, world_size)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mvalid_loaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mvalid_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             )\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/train/train.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader, lang_loaders, epoch, valid_loaders, log_interval, valid_interval, path)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtrain_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_tb_log_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/train/train.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, batch, lang_iters, epoch)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mtotal_lang_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_multilanguage_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtotal_lang_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "        train_loader=train_loader,\n",
    "        valid_loaders=val_loaders,\n",
    "        lang_loaders=adapt_loaders,\n",
    "        nb_epochs=opt.engine.nb_epochs,\n",
    "        valid_interval=opt.engine.valid_interval,\n",
    "        log_interval=opt.engine.print_freq\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34246268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910cc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86452f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "459ad4e7",
   "metadata": {},
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0cf190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(3, 3, device=\"cuda:0\")\n",
    "a = torch.mm(a, a.t()) # make symmetric positive-definite\n",
    "torch.cholesky(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738f10",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "image_id = train_loader.dataset.data_wrapper.image_ids[index]\n",
    "caption = train_loader.dataset.captions[index]\n",
    "cap_tokens = train_loader.dataset.tokenizer(caption)\n",
    "image = train_loader.dataset.load_img(image_id)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image.permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae5e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.max(list(train_loader.dataset.data_wrapper.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader.dataset.captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a127e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "05ed003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check valid loader\n",
    "#image_id2 = val_loaders[0].dataset.data_wrapper.image_ids[index]\n",
    "#image2 = val_loaders[0].dataset.load_img(image_id2)\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.imshow(  image2.permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1d06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
