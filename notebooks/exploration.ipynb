{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fd7420",
   "metadata": {},
   "source": [
    "# Exploration of execution\n",
    "\n",
    "Execution \n",
    "\n",
    "```{bash}\n",
    "cd /home/ec2-user/SageMaker/foodi-ml\n",
    "source activate python3\n",
    "export DATA_PATH=/home/ec2-user/SageMaker/data/\n",
    "python run.py options/adapt/foodi-ml/i2t.yaml\n",
    "\n",
    "#nvidia-smi\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5608f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/ec2-user/SageMaker/foodi-ml/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87448054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32167841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f60728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import params\n",
    "from retrieval.train import train\n",
    "from retrieval.utils import helper\n",
    "from retrieval.model import loss\n",
    "from retrieval.model.model import Retrieval\n",
    "from retrieval.data.loaders import get_loaders\n",
    "from retrieval.utils.logger import create_logger\n",
    "from retrieval.utils.helper import load_model\n",
    "from retrieval.utils.file_utils import load_yaml_opts, parse_loader_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0650788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from addict import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a6a0f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820f2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(opt):\n",
    "    if 'DATA_PATH' not in os.environ:\n",
    "        if not opt.dataset.data_path:\n",
    "            raise Exception('''\n",
    "                DATA_PATH not specified.\n",
    "                Please, run \"$ export DATA_PATH=/path/to/dataset\"\n",
    "                or add path to yaml file\n",
    "            ''')\n",
    "        return opt.dataset.data_path\n",
    "    else:\n",
    "        return os.environ['DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268c186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizers(train_loader):\n",
    "    tokenizers = train_loader.dataset.tokenizer\n",
    "    if type(tokenizers) != list:\n",
    "        tokenizers = [tokenizers]\n",
    "    return tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aec1de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_criterion(opt, model):\n",
    "    if 'name' in opt.criterion:\n",
    "        logger.info(opt.criterion)\n",
    "        multimodal_criterion = loss.get_loss(**opt.criterion)\n",
    "        multilanguage_criterion = loss.get_loss(**opt.criterion)\n",
    "    else:\n",
    "        multimodal_criterion = loss.ContrastiveLoss(**opt.criterion)\n",
    "        multilanguage_criterion = loss.ContrastiveLoss(**opt.ml_criterion)\n",
    "    set_model_criterion(opt, model, multilanguage_criterion, multimodal_criterion)\n",
    "    # return multimodal_criterion, multilanguage_criterion\n",
    "\n",
    "\n",
    "def set_model_criterion(opt, model, multilanguage_criterion, multimodal_criterion):\n",
    "    model.mm_criterion = multimodal_criterion\n",
    "    model.ml_criterion = None\n",
    "    if len(opt.dataset.adapt.data) > 0:\n",
    "        model.ml_criterion = multilanguage_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76937dce",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13ba77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATA_PATH\"] = \"/home/ec2-user/SageMaker/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d425a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = \"options/adapt/foodi-ml/i2t.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a686dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"options\": options,\n",
    "}\n",
    "args = Dict(args)\n",
    "opt = load_yaml_opts(args.options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1752b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = create_logger(level='debug' if opt.engine.debug else 'info')\n",
    "#logger.info(f'Used args   : \\n{args}')\n",
    "#logger.info(f'Used options: \\n{opt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "284b6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path of the data\n",
    "data_path = get_data_path(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75e04bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 13:32:05,903 - [INFO    ] - Loaded vocab containing 2487 tokens\n",
      "2021-08-17 13:32:05,904 - [INFO    ] - Loaded from .vocab_cache/foodiml_vocab.json.\n",
      "2021-08-17 13:32:05,904 - [INFO    ] - Created tokenizer with init 2487 tokens.\n",
      "2021-08-17 13:32:05,947 - [INFO    ] - [FoodiML] Loaded 8011 images and 8011 annotations.\n",
      "2021-08-17 13:32:05,951 - [INFO    ] - Loaded vocab containing 2487 tokens\n",
      "2021-08-17 13:32:05,952 - [INFO    ] - Loaded from .vocab_cache/foodiml_vocab.json.\n",
      "2021-08-17 13:32:05,952 - [INFO    ] - Created tokenizer with init 2487 tokens.\n",
      "2021-08-17 13:32:05,987 - [INFO    ] - [FoodiML] Loaded 0 images and 0 annotations.\n",
      "2021-08-17 13:32:05,988 - [INFO    ] - Adapt loaders: 0\n"
     ]
    }
   ],
   "source": [
    "# Get loaders\n",
    "train_loader, val_loaders, adapt_loaders = get_loaders(data_path, args.local_rank, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8458178",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = get_tokenizers(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1be7e27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 13:32:08,684 - [INFO    ] - Image encoder created: ('full_image',)\n",
      "2021-08-17 13:32:08,973 - [INFO    ] - Text encoder created: gru_glove\n",
      "2021-08-17 13:32:09,043 - [INFO    ] - Created similarity: AdaptiveEmbeddingI2T(\n",
      "  (norm): Normalization(\n",
      "    (norm): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  )\n",
      "  (adapt_txt): ADAPT(\n",
      "    (fc_gamma): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    )\n",
      "    (fc_beta): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fovea): Fovea(smooth=10,train_smooth: False)\n",
      ")\n",
      "2021-08-17 13:32:09,190 - [INFO    ] - Setting devices: img: cuda,txt: cuda, loss: cuda\n",
      "2021-08-17 13:32:09,190 - [INFO    ] - Using similarity: ('adapt_i2t',)\n"
     ]
    }
   ],
   "source": [
    "model = Retrieval(**opt.model, tokenizers=tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1d6a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_fn = (lambda x: x) if not model.master else tqdm.write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e12838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_criterion(opt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0160f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = train.Trainer(\n",
    "        model=model,\n",
    "        args=opt,\n",
    "        sysoutlog=print_fn,\n",
    "        path=opt.exp.outpath,\n",
    "        world_size=1 # TODO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cfa13de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 13:32:12,691 - [INFO    ] - lr 0.001\n",
      "2021-08-17 13:32:12,692 - [INFO    ] - [0.5, 2.0, 4000]\n",
      "2021-08-17 13:32:12,692 - [INFO    ] - [10000, 20000, 3000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing model.txt_enc.embed.glove\n",
      "lr: 0.001, #layers: 478, #params: 99,845,812\n",
      "Total Params: 102,349,912, \n"
     ]
    }
   ],
   "source": [
    "trainer.setup_optim(\n",
    "        lr=opt.optimizer.lr,\n",
    "        lr_scheduler=opt.optimizer.lr_scheduler,\n",
    "        clip_grad=opt.optimizer.grad_clip,\n",
    "        log_grad_norm=False,\n",
    "        log_histograms=False,\n",
    "        optimizer=opt.optimizer,\n",
    "        freeze_modules=opt.model.freeze_modules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e62cadd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "logs/foodi-ml/adapt_i2t/ already exists! Do you want to rewrite it? [y/n]  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Steps :   0%|          | 0/802 [00:00<?, ?it/s]\u001b[A\n",
      "Steps :   0%|          | 1/802 [00:00<08:31,  1.57it/s]\u001b[A\n",
      "Steps :   0%|          | 2/802 [00:01<07:12,  1.85it/s]\u001b[A\n",
      "Steps :   0%|          | 3/802 [00:01<06:43,  1.98it/s]\u001b[A\n",
      "Steps :   0%|          | 4/802 [00:01<06:31,  2.04it/s]\u001b[A\n",
      "Steps :   1%|          | 5/802 [00:02<06:16,  2.12it/s]\u001b[A\n",
      "Steps :   1%|          | 6/802 [00:02<06:07,  2.17it/s]\u001b[A\n",
      "Steps :   1%|          | 7/802 [00:03<06:02,  2.19it/s]\u001b[A\n",
      "Steps :   1%|          | 8/802 [00:03<05:56,  2.23it/s]\u001b[A\n",
      "                                              2.23it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/30 [00:04<?, ?it/s]         \n",
      "Steps :   1%|          | 9/802 [00:04<06:33,  2.02it/s]\u001b[A\n",
      "Steps :   1%|          | 10/802 [00:04<05:53,  2.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.407761, Countdown:  50.000000, Epoch:   0.000000, Iteration:  10.000000, K:   0.086441, Loss:  33.452599, Lr_Base:   0.000504, Norm: 117.124039, Total_Loss:  33.452599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   1%|▏         | 11/802 [00:04<05:52,  2.25it/s]\u001b[A\n",
      "Steps :   1%|▏         | 12/802 [00:05<05:50,  2.26it/s]\u001b[A\n",
      "Steps :   2%|▏         | 13/802 [00:05<05:48,  2.26it/s]\u001b[A\n",
      "Steps :   2%|▏         | 14/802 [00:06<05:45,  2.28it/s]\u001b[A\n",
      "Steps :   2%|▏         | 15/802 [00:06<05:44,  2.29it/s]\u001b[A\n",
      "Steps :   2%|▏         | 16/802 [00:06<05:43,  2.29it/s]\u001b[A\n",
      "Steps :   2%|▏         | 17/802 [00:07<05:41,  2.30it/s]\u001b[A\n",
      "Steps :   2%|▏         | 18/802 [00:07<05:41,  2.30it/s]\u001b[A\n",
      "                                               2.31it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/30 [00:08<?, ?it/s]          \n",
      "Steps :   2%|▏         | 19/802 [00:08<05:56,  2.19it/s]\u001b[A\n",
      "Steps :   2%|▏         | 20/802 [00:08<05:38,  2.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.396405, Countdown:  50.000000, Epoch:   0.000000, Iteration:  20.000000, K:   0.165410, Loss:  30.421429, Lr_Base:   0.000508, Norm:  94.119436, Total_Loss:  30.421429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   3%|▎         | 21/802 [00:09<05:37,  2.32it/s]\u001b[A\n",
      "Steps :   3%|▎         | 22/802 [00:09<05:36,  2.32it/s]\u001b[A\n",
      "Steps :   3%|▎         | 23/802 [00:09<05:34,  2.33it/s]\u001b[A\n",
      "Steps :   3%|▎         | 24/802 [00:10<05:35,  2.32it/s]\u001b[A\n",
      "Steps :   3%|▎         | 25/802 [00:10<05:34,  2.32it/s]\u001b[A\n",
      "Steps :   3%|▎         | 26/802 [00:11<05:33,  2.33it/s]\u001b[A\n",
      "Steps :   3%|▎         | 27/802 [00:11<05:32,  2.33it/s]\u001b[A\n",
      "Steps :   3%|▎         | 28/802 [00:12<05:32,  2.33it/s]\u001b[A\n",
      "                                               2.33it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/30 [00:12<?, ?it/s]          \n",
      "Steps :   4%|▎         | 29/802 [00:12<05:43,  2.25it/s]\u001b[A\n",
      "Steps :   4%|▎         | 30/802 [00:12<05:31,  2.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.397878, Countdown:  50.000000, Epoch:   0.000000, Iteration:  30.000000, K:   0.237553, Loss:  27.757206, Lr_Base:   0.000511, Norm:  97.159623, Total_Loss:  27.757206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   4%|▍         | 31/802 [00:13<05:30,  2.33it/s]\u001b[A\n",
      "Steps :   4%|▍         | 32/802 [00:13<05:29,  2.33it/s]\u001b[A\n",
      "Steps :   4%|▍         | 33/802 [00:14<05:29,  2.33it/s]\u001b[A\n",
      "Steps :   4%|▍         | 34/802 [00:14<05:29,  2.33it/s]\u001b[A\n",
      "Steps :   4%|▍         | 35/802 [00:14<05:28,  2.33it/s]\u001b[A\n",
      "Steps :   4%|▍         | 36/802 [00:15<05:28,  2.34it/s]\u001b[A\n",
      "Steps :   5%|▍         | 37/802 [00:15<05:27,  2.34it/s]\u001b[A\n",
      "Steps :   5%|▍         | 38/802 [00:16<05:26,  2.34it/s]\u001b[A\n",
      "                                               2.34it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/30 [00:17<?, ?it/s]          \n",
      "Steps :   5%|▍         | 39/802 [00:17<05:34,  2.28it/s]\u001b[A\n",
      "Steps :   5%|▍         | 40/802 [00:17<05:25,  2.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.402119, Countdown:  50.000000, Epoch:   0.000000, Iteration:  40.000000, K:   0.303460, Loss:  27.810789, Lr_Base:   0.000515, Norm:  99.816655, Total_Loss:  27.810789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   5%|▌         | 41/802 [00:17<05:25,  2.34it/s]\u001b[A\n",
      "Steps :   5%|▌         | 42/802 [00:17<05:24,  2.34it/s]\u001b[A\n",
      "Steps :   5%|▌         | 43/802 [00:18<05:23,  2.34it/s]\u001b[A\n",
      "Steps :   5%|▌         | 44/802 [00:18<05:22,  2.35it/s]\u001b[A\n",
      "Steps :   6%|▌         | 45/802 [00:19<05:23,  2.34it/s]\u001b[A\n",
      "Steps :   6%|▌         | 46/802 [00:19<05:22,  2.34it/s]\u001b[A\n",
      "Steps :   6%|▌         | 47/802 [00:20<05:22,  2.34it/s]\u001b[A\n",
      "Steps :   6%|▌         | 48/802 [00:20<05:21,  2.34it/s]\u001b[A\n",
      "                                               2.35it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/30 [00:21<?, ?it/s]          \n",
      "Steps :   6%|▌         | 49/802 [00:21<05:28,  2.29it/s]\u001b[A\n",
      "Steps :   6%|▌         | 50/802 [00:21<05:21,  2.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.432125, Countdown:  50.000000, Epoch:   0.000000, Iteration:  50.000000, K:   0.363670, Loss:  23.769077, Lr_Base:   0.000519, Norm:  80.032136, Total_Loss:  23.769077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   6%|▋         | 51/802 [00:21<05:20,  2.34it/s]\u001b[A\n",
      "Steps :   6%|▋         | 52/802 [00:22<05:20,  2.34it/s]\u001b[A\n",
      "Steps :   7%|▋         | 53/802 [00:22<05:19,  2.35it/s]\u001b[A\n",
      "Steps :   7%|▋         | 54/802 [00:23<05:18,  2.35it/s]\u001b[A\n",
      "Steps :   7%|▋         | 55/802 [00:23<05:18,  2.35it/s]\u001b[A\n",
      "Steps :   7%|▋         | 56/802 [00:23<05:17,  2.35it/s]\u001b[A\n",
      "Steps :   7%|▋         | 57/802 [00:24<05:16,  2.35it/s]\u001b[A\n",
      "Steps :   7%|▋         | 58/802 [00:24<05:16,  2.35it/s]\u001b[A\n",
      "                                               2.35it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/30 [00:25<?, ?it/s]          \n",
      "Steps :   7%|▋         | 59/802 [00:25<05:21,  2.31it/s]\u001b[A\n",
      "Steps :   7%|▋         | 60/802 [00:25<05:16,  2.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.414315, Countdown:  50.000000, Epoch:   0.000000, Iteration:  60.000000, K:   0.418675, Loss:  22.035759, Lr_Base:   0.000523, Norm:  77.604154, Total_Loss:  22.035759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   8%|▊         | 61/802 [00:25<05:15,  2.35it/s]\u001b[A\n",
      "Steps :   8%|▊         | 62/802 [00:26<05:15,  2.35it/s]\u001b[A\n",
      "Steps :   8%|▊         | 63/802 [00:26<05:14,  2.35it/s]\u001b[A\n",
      "Steps :   8%|▊         | 64/802 [00:27<05:14,  2.35it/s]\u001b[A\n",
      "Steps :   8%|▊         | 65/802 [00:27<05:13,  2.35it/s]\u001b[A\n",
      "Steps :   8%|▊         | 66/802 [00:28<05:13,  2.35it/s]\u001b[A\n",
      "Steps :   8%|▊         | 67/802 [00:28<05:13,  2.35it/s]\u001b[A\n",
      "Steps :   8%|▊         | 68/802 [00:28<05:12,  2.35it/s]\u001b[A\n",
      "                                               2.35it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/30 [00:29<?, ?it/s]          \n",
      "Steps :   9%|▊         | 69/802 [00:29<05:17,  2.31it/s]\u001b[A\n",
      "Steps :   9%|▊         | 70/802 [00:29<05:12,  2.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.447006, Countdown:  50.000000, Epoch:   0.000000, Iteration:  70.000000, K:   0.468925, Loss:  20.099714, Lr_Base:   0.000526, Norm:  68.479503, Total_Loss:  20.099714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :   9%|▉         | 71/802 [00:30<05:12,  2.34it/s]\u001b[A\n",
      "Steps :   9%|▉         | 72/802 [00:30<05:11,  2.34it/s]\u001b[A\n",
      "Steps :   9%|▉         | 73/802 [00:31<05:11,  2.34it/s]\u001b[A\n",
      "Steps :   9%|▉         | 74/802 [00:31<05:10,  2.34it/s]\u001b[A\n",
      "Steps :   9%|▉         | 75/802 [00:32<05:10,  2.34it/s]\u001b[A\n",
      "Steps :   9%|▉         | 76/802 [00:32<05:09,  2.34it/s]\u001b[A\n",
      "Steps :  10%|▉         | 77/802 [00:32<05:09,  2.34it/s]\u001b[A\n",
      "Steps :  10%|▉         | 78/802 [00:33<05:09,  2.34it/s]\u001b[A\n",
      "                                               2.34it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/30 [00:34<?, ?it/s]          \n",
      "Steps :  10%|▉         | 79/802 [00:34<05:12,  2.31it/s]\u001b[A\n",
      "Steps :  10%|▉         | 80/802 [00:34<05:08,  2.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_Time:   0.416992, Countdown:  50.000000, Epoch:   0.000000, Iteration:  80.000000, K:   0.514832, Loss:  19.593702, Lr_Base:   0.000530, Norm:  66.754051, Total_Loss:  19.593702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps :  10%|█         | 81/802 [00:34<05:07,  2.34it/s]\u001b[A\n",
      "Steps :  10%|█         | 82/802 [00:35<05:07,  2.34it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fb0f5dc0a185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalid_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/train/train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, valid_loaders, lang_loaders, init_iteration, nb_epochs, log_interval, valid_interval, world_size)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mvalid_loaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mvalid_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             )\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/train/train.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader, lang_loaders, epoch, valid_loaders, log_interval, valid_interval, path)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mtrain_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_tb_log_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/train/train.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, batch, lang_iters, epoch)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mbegin_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mmultimodal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_multimodal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mtotal_lang_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_multilanguage_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtotal_lang_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/train/train.py\u001b[0m in \u001b[0;36m_forward_multimodal_loss\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_multimodal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mimg_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0msim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sim_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/model/model.py\u001b[0m in \u001b[0;36mforward_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mimg_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mtxt_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_captions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/model/model.py\u001b[0m in \u001b[0;36membed_captions\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_captions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mtxt_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mtxt_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_caption_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtxt_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/model/txtenc/txtenc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[1;32m     57\u001b[0m         \u001b[0mcaptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mcaptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Embed word ids to vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "        train_loader=train_loader,\n",
    "        valid_loaders=val_loaders,\n",
    "        lang_loaders=adapt_loaders,\n",
    "        nb_epochs=opt.engine.nb_epochs,\n",
    "        valid_interval=opt.engine.valid_interval,\n",
    "        log_interval=opt.engine.print_freq\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "752cfcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c8361cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5002,  0.0000,  0.0000],\n",
       "        [-0.5008,  1.0633,  0.0000],\n",
       "        [ 0.0642,  0.4374,  1.6847]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(3, 3, device=\"cuda:0\")\n",
    "a = torch.mm(a, a.t()) # make symmetric positive-definite\n",
    "torch.cholesky(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd914c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
