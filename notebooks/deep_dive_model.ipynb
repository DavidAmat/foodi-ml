{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1709e8b0",
   "metadata": {},
   "source": [
    "# DEEP DIVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2cb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/ec2-user/SageMaker/foodi-ml/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046c92e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed80335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import params\n",
    "from retrieval.train import train\n",
    "from retrieval.utils import helper\n",
    "from retrieval.model import loss\n",
    "from retrieval.model.model import Retrieval\n",
    "from retrieval.data.loaders import get_loaders\n",
    "from retrieval.utils.logger import create_logger\n",
    "from retrieval.utils.helper import load_model\n",
    "from retrieval.utils.file_utils import load_yaml_opts, parse_loader_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2697f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from addict import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e00834",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79524cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(opt):\n",
    "    if 'DATA_PATH' not in os.environ:\n",
    "        if not opt.dataset.data_path:\n",
    "            raise Exception('''\n",
    "                DATA_PATH not specified.\n",
    "                Please, run \"$ export DATA_PATH=/path/to/dataset\"\n",
    "                or add path to yaml file\n",
    "            ''')\n",
    "        return opt.dataset.data_path\n",
    "    else:\n",
    "        return os.environ['DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feeb8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizers(train_loader):\n",
    "    tokenizers = train_loader.dataset.tokenizer\n",
    "    if type(tokenizers) != list:\n",
    "        tokenizers = [tokenizers]\n",
    "    return tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf0d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_criterion(opt, model):\n",
    "    if 'name' in opt.criterion:\n",
    "        logger.info(opt.criterion)\n",
    "        multimodal_criterion = loss.get_loss(**opt.criterion)\n",
    "        multilanguage_criterion = loss.get_loss(**opt.criterion)\n",
    "    else:\n",
    "        multimodal_criterion = loss.ContrastiveLoss(**opt.criterion)\n",
    "        multilanguage_criterion = loss.ContrastiveLoss(**opt.ml_criterion)\n",
    "    set_model_criterion(opt, model, multilanguage_criterion, multimodal_criterion)\n",
    "    # return multimodal_criterion, multilanguage_criterion\n",
    "\n",
    "\n",
    "def set_model_criterion(opt, model, multilanguage_criterion, multimodal_criterion):\n",
    "    model.mm_criterion = multimodal_criterion\n",
    "    model.ml_criterion = None\n",
    "    if len(opt.dataset.adapt.data) > 0:\n",
    "        model.ml_criterion = multilanguage_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4157e10a",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa78f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATA_PATH\"] = \"/home/ec2-user/SageMaker/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f376ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = \"options/adapt/foodi-ml/i2t.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "260b0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"options\": options,\n",
    "}\n",
    "args = Dict(args)\n",
    "opt = load_yaml_opts(args.options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38959467",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = create_logger(level='debug' if opt.engine.debug else 'info')\n",
    "#logger.info(f'Used args   : \\n{args}')\n",
    "#logger.info(f'Used options: \\n{opt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f1780b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path of the data\n",
    "data_path = get_data_path(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf66873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 18:56:03,824 - [INFO    ] - Loaded vocab containing 2487 tokens\n",
      "2021-08-16 18:56:03,824 - [INFO    ] - Loaded from .vocab_cache/foodiml_vocab.json.\n",
      "2021-08-16 18:56:03,825 - [INFO    ] - Created tokenizer with init 2487 tokens.\n",
      "2021-08-16 18:56:03,868 - [INFO    ] - [FoodiML] Loaded 8011 images and 8011 annotations.\n",
      "2021-08-16 18:56:03,873 - [INFO    ] - Loaded vocab containing 2487 tokens\n",
      "2021-08-16 18:56:03,873 - [INFO    ] - Loaded from .vocab_cache/foodiml_vocab.json.\n",
      "2021-08-16 18:56:03,873 - [INFO    ] - Created tokenizer with init 2487 tokens.\n",
      "2021-08-16 18:56:03,910 - [INFO    ] - [FoodiML] Loaded 0 images and 0 annotations.\n",
      "2021-08-16 18:56:03,910 - [INFO    ] - Adapt loaders: 0\n"
     ]
    }
   ],
   "source": [
    "# Get loaders\n",
    "train_loader, val_loaders, adapt_loaders = get_loaders(data_path, args.local_rank, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed70f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = get_tokenizers(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "114aacf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 18:56:04,555 - [INFO    ] - Image encoder created: ('resnet50',)\n",
      "2021-08-16 18:56:04,662 - [INFO    ] - Text encoder created: gru_glove\n",
      "2021-08-16 18:56:04,663 - [INFO    ] - Created similarity: Cosine()\n",
      "2021-08-16 18:56:07,547 - [INFO    ] - Setting devices: img: cuda,txt: cuda, loss: cuda\n",
      "2021-08-16 18:56:07,548 - [INFO    ] - Using similarity: ('cosine',)\n"
     ]
    }
   ],
   "source": [
    "model = Retrieval(**opt.model, tokenizers=tokenizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d8460",
   "metadata": {},
   "source": [
    "<font color='red'> **Deep dive on Retrieval --------------------- (1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f0cd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval.model.model import Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72a993a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.model['img_enc']['name'] = 'resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87b1d10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 18:56:08,177 - [INFO    ] - Image encoder created: ('resnet50',)\n",
      "2021-08-16 18:56:08,283 - [INFO    ] - Text encoder created: gru_glove\n",
      "2021-08-16 18:56:08,284 - [INFO    ] - Created similarity: Cosine()\n",
      "2021-08-16 18:56:08,337 - [INFO    ] - Setting devices: img: cuda,txt: cuda, loss: cuda\n",
      "2021-08-16 18:56:08,338 - [INFO    ] - Using similarity: ('cosine',)\n"
     ]
    }
   ],
   "source": [
    "model = Retrieval(**opt.model, tokenizers=tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c17145e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_enc = model.txt_enc\n",
    "img_enc = model.img_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a15b9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_pool = model.txt_pool \n",
    "img_pool = model.img_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6052ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_loader = iter(train_loader)\n",
    "batch = next(gen_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5818ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(gen_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93685b90",
   "metadata": {},
   "source": [
    "#### Images embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a44183d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00950b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = batch['image']\n",
    "input_batch = input_batch.to(model.img_enc.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0586546",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = img_enc(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9fcb6e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_batch: \t torch.Size([10, 3, 224, 224])\n",
      "img_tensor: \t torch.Size([10, 49, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_batch: \\t\", input_batch.shape)\n",
    "print(\"img_tensor: \\t\", img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f4584b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embed  = model.embed_image_features(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5580a148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullImageEncoder(\n",
       "  (cnn): BaseFeatures(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (region_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=2048, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e0faf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_enc.proj_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527815d",
   "metadata": {},
   "source": [
    "#### Text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67478b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd19c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_tensor, lengths = txt_enc(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9072e57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 25, 1024])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7896850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_tensor = model.embed_caption_features(txt_tensor, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3ea42ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 25, 1024])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "995b06bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 8, 13, 12, 19, 20, 25, 11, 24, 8]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "257940d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 25])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['caption'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5963c10",
   "metadata": {},
   "source": [
    "#### Forward batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a96870b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embed, txt_embed = model.forward_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34f9dca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 49, 1024])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0588de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 25, 1024])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9650e1b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-4650f6b8d8d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sim_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/model/model.py\u001b[0m in \u001b[0;36mget_sim_matrix\u001b[0;34m(self, embed_a, embed_b, lens)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sim_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_ml_sim_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/model/similarity/similarity.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img_embed, cap_embed, lens, shared)\u001b[0m\n\u001b[1;32m     40\u001b[0m         ))\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/model/similarity/similarity.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img_embed, cap_embed, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mcap_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.cpu()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/foodi-ml/retrieval/model/similarity/measure.py\u001b[0m in \u001b[0;36mcosine_sim\u001b[0;34m(im, s)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msentence\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \"\"\"\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 3D"
     ]
    }
   ],
   "source": [
    "model.get_sim_matrix(img_embed, txt_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3988724f",
   "metadata": {},
   "source": [
    "<font color='red'> **Finish Deep dive on Retrieval --------------------- (1)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
