{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ddba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "import shutil\n",
    "\n",
    "os.chdir(\"/home/ec2-user/SageMaker/foodi-ml/notebooks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a78a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386fb6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_aws = reload(utils_aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5b5e7",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c730a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = '/home/ec2-user/SageMaker/dataset'\n",
    "PATH_FOODI = '/home/ec2-user/SageMaker/foodi-ml'\n",
    "DATASET_CSV = 'glovo-foodi-ml-dataset.csv'\n",
    "\n",
    "conf = {\n",
    "    \"S3_BUCKET\": 'glovo-products-dataset-d1c9720d',\n",
    "    \"S3_KEY_DATASET\": DATASET_CSV,\n",
    "    \"LOCAL_RAW_DATASET\": os.path.join(PATH_DATA, DATASET_CSV),\n",
    "    \"LOCAL_DATASET\": os.path.join(PATH_DATA, 'samples'),\n",
    "    \"LOCAL_IMAGES\": os.path.join(PATH_DATA, 'dataset'),\n",
    "    \"LOCAL_VOCAB\": os.path.join(PATH_FOODI, '.vocab_cache/foodiml_vocab.json'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91294791",
   "metadata": {},
   "source": [
    "# AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53aaea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS classes\n",
    "#aws_con = utils_aws.AWSConnector(conf[\"S3_BUCKET\"])\n",
    "#awstools = utils_aws.AWSTools(aws_con)\n",
    "#aws_basics = utils_aws.AWSBasics(conf[\"S3_BUCKET\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aee79d",
   "metadata": {},
   "source": [
    "# Download csv (glovo-foodi-ml-dataset.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebec837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#command = f'aws s3 cp s3://{conf[\"S3_BUCKET\"]}/{conf[\"S3_KEY_DATASET\"]} {conf[\"LOCAL_RAW_DATASET\"]} --no-sign-request'\n",
    "#os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed607b",
   "metadata": {},
   "source": [
    "# Read all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe874a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv(os.path.join(conf['LOCAL_RAW_DATASET']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b35c4",
   "metadata": {},
   "source": [
    "## 1) Create sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7120a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[\"sentence\"] = \\\n",
    "    np.where(samples[\"product_name\"], samples[\"product_name\"].astype(str), \"\") + \" \" + \\\n",
    "    np.where(samples[\"collection_section\"], samples[\"collection_section\"].astype(str), \"\") + \" \" + \\\n",
    "    np.where(samples[\"product_description\"], samples[\"product_description\"].astype(str), \"\")\n",
    "\n",
    "samples[\"sentence\"] = samples[\"sentence\"].str.lower()\n",
    "samples.rename(columns={'Unnamed: 0': 'idx'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e911009a",
   "metadata": {},
   "source": [
    "### 1.1) Fit tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a4efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH_FOODI)\n",
    "from retrieval.data.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc5a716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "# 1) Get all sentences \n",
    "sentences = samples[\"sentence\"].values\n",
    "\n",
    "# 2) Fit Tokenizer with senteces (CAREFUL, takes 6-7 min)\n",
    "tokenizer = Tokenizer(vocab_path=None, download_tokenizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a180da73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2887444/2887444 [06:49<00:00, 7048.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fit tokenize\n",
    "vocab = tokenizer.fit(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9634071d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245967"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b8c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 330 ms, sys: 4.02 ms, total: 334 ms\n",
      "Wall time: 342 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3) Saving vocabulary\n",
    "tokenizer.save(conf['LOCAL_VOCAB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353efca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Load if already saved\n",
    "tokenizer = tokenizer.load(conf['LOCAL_VOCAB'])\n",
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399d8ff7",
   "metadata": {},
   "source": [
    "### 1.2) Creating dataset parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d832d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only necessary columns for modelling\n",
    "final_samples = samples[[\"sentence\", \"s3_path\", \"subset\"]].reset_index().copy()\n",
    "final_samples.rename(columns={\"sentence\": \"caption\"}, inplace=True)\n",
    "final_samples.rename(columns={\"subset\": \"split\"}, inplace=True)\n",
    "final_samples.rename(columns={\"index\": \"img_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e607b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous version\n",
    "if os.path.exists(conf[\"LOCAL_DATASET\"]):\n",
    "    shutil.rmtree(conf[\"LOCAL_DATASET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eeea339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as partitioned parquet\n",
    "final_samples.to_parquet(\n",
    "    path=conf[\"LOCAL_DATASET\"],\n",
    "    engine=\"pyarrow\",\n",
    "    index=False,\n",
    "    partition_cols=[\"split\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "83b4e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_samples = pd.read_parquet(path=os.path.join(conf[\"LOCAL_DATASET\"],'split=val'), engine=\"pyarrow\")\n",
    "#valid_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed6953",
   "metadata": {},
   "source": [
    "### 1.3) Downloading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69911078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor\n",
    "from multiprocessing import Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3afb3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create in images the train/test/valid split\n",
    "for split in final_samples.split.unique():\n",
    "    os.makedirs(os.path.join(conf[\"LOCAL_IMAGES\"], split), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79541420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change to all images (remove head)\n",
    "img_samples = final_samples.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d93a9848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>s3_path</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>savital shampoo keratina y sabila 550ml (00001...</td>\n",
       "      <td>dataset/NZTCKFL_0017467_1193055503.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chocolate layer cake™ promotions - free waffle...</td>\n",
       "      <td>dataset/YKKVTDF_0000672_1629430873.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>асорті на компанію закуски балик домашній,груд...</td>\n",
       "      <td>dataset/ZFSHHGC_0000633_24100453.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>suav vivere hierbas f jazmin pouch 900cc suavi...</td>\n",
       "      <td>dataset/NZTCKFL_0025186_1197233181.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>leoncio y el doctor veterinario infantil nan</td>\n",
       "      <td>dataset/NZTCKFL_0061335_1296271395.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   img_id                                            caption  \\\n",
       "0       0  savital shampoo keratina y sabila 550ml (00001...   \n",
       "1       1  chocolate layer cake™ promotions - free waffle...   \n",
       "2       2  асорті на компанію закуски балик домашній,груд...   \n",
       "3       3  suav vivere hierbas f jazmin pouch 900cc suavi...   \n",
       "4       4       leoncio y el doctor veterinario infantil nan   \n",
       "\n",
       "                                  s3_path  split  \n",
       "0  dataset/NZTCKFL_0017467_1193055503.png  train  \n",
       "1  dataset/YKKVTDF_0000672_1629430873.png  train  \n",
       "2    dataset/ZFSHHGC_0000633_24100453.png  train  \n",
       "3  dataset/NZTCKFL_0025186_1197233181.png  train  \n",
       "4  dataset/NZTCKFL_0061335_1296271395.png  train  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2b224a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_img(s3_path, local_pth):\n",
    "    command = f'aws s3 cp s3://{conf[\"S3_BUCKET\"]}/{s3_path} {local_pth} --no-sign-request'\n",
    "    result = os.system(command)\n",
    "    if result == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f42abb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 29.1 s, total: 29.3 s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ----------------------------- #\n",
    "#  Threading Download S3 images\n",
    "# ----------------------------- #\n",
    "THREADS = 8\n",
    "d_download = Manager().dict()\n",
    "images_dict = {}\n",
    "\n",
    "# Request to Danzai API\n",
    "with ProcessPoolExecutor(max_workers=THREADS) as executor:\n",
    "\n",
    "    # Populate the images_dict dictionary\n",
    "    for _, row in img_samples.iterrows():\n",
    "        s3_path = row[\"s3_path\"]\n",
    "        train_test_split = row[\"split\"]\n",
    "        s3_img = s3_path.split(\"/\")[-1]\n",
    "        \n",
    "        # Use the split to download the image to a specific directory\n",
    "        local_pth = os.path.join(conf[\"LOCAL_IMAGES\"], train_test_split, s3_img)\n",
    "        \n",
    "        images_dict[\n",
    "            executor.submit(download_img, s3_path, local_pth)\n",
    "        ] = s3_img\n",
    "\n",
    "        # Start running threads\n",
    "    for i_future in as_completed(images_dict):\n",
    "        image_id = images_dict[i_future]\n",
    "        try:\n",
    "            d_download[image_id] = i_future.result()\n",
    "        except Exception:\n",
    "            d_download[image_id] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e34fd5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = dict(d_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0024e09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(conf[\"LOCAL_IMAGES\"], \"train\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056b2b9",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ed1a5",
   "metadata": {},
   "source": [
    "# GloVE (in case we want to retrain a new GloVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fed1d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glove_python\n",
      "  Downloading glove_python-0.1.0.tar.gz (263 kB)\n",
      "\u001b[K     |████████████████████████████████| 263 kB 35.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from glove_python) (1.16.2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from glove_python) (1.5.3)\n",
      "Building wheels for collected packages: glove-python\n",
      "  Building wheel for glove-python (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for glove-python: filename=glove_python-0.1.0-cp36-cp36m-linux_x86_64.whl size=781088 sha256=b49ad1beca1ce5af45cc41f82001a84929ae3124dea2679f996b910044c2fadd\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c2/34/66/a3adc1e41bd5cfe3aa8f75e34b42ca207f8b6e8171b9a4fd61\n",
      "Successfully built glove-python\n",
      "Installing collected packages: glove-python\n",
      "Successfully installed glove-python-0.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install glove_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10455913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ce82ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a corpus object\n",
    "corpus = Corpus() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26c594ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(final_samples[\"caption\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c18c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for sentence in tqdm.tqdm(sentences[:50000]):\n",
    "    lines.append(tokenizer.split_sentence(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bdfbfcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.29 s, sys: 12.1 ms, total: 1.3 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
    "corpus.fit(lines, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e76269a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "glove = Glove(no_components=5, learning_rate=0.05) \n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "glove.save('/home/ec2-user/SageMaker/data/glove/glove-foodiml.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
